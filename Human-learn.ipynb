{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b37997c-84fe-4eba-aaf2-3a80cdcb220c",
   "metadata": {},
   "source": [
    "Human-Learn is a library that helps people create and test rule-based systems that work well with scikit-learn tools. It's designed to make it easier for humans to build and evaluate these systems, and you can also use it alongside machine learning models for even better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226c7ae-e9a7-4abf-a081-3599132d14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install the package if you haven't already\n",
    "# python -m pip install human-learn\n",
    "\n",
    "from hulearn.datasets import load_titanic\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da334cf2-ae33-4ccf-9fc4-93feb10e6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "df = load_titanic(as_frame=True)\n",
    "X, y = df.drop(columns=['survived']), df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296bc7d-6b3b-432a-828a-45bef7260f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fare_based function for classification\n",
    "def fare_based(dataf, threshold=10):\n",
    "    return np.array(dataf['fare'] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0947a31-1b0f-40e2-95f7-a30e31f4faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Predict survival based on whether the fare is above a threshold (default threshold is 10)\n",
    "predictions = fare_based(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f350f-406e-4e72-a865-d22dec3fb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85f05d-9535-49fc-a9c8-f5d6e10937de",
   "metadata": {},
   "source": [
    "FunctionClassifier from the Human-Learn library in a scikit-learn pipeline for classification tasks with the Titanic dataset and grid search for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85686c57-00ea-4309-bdb3-2fbe6b77110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hulearn.datasets import load_titanic\n",
    "from hulearn.classification import FunctionClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, make_scorer\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = load_titanic(as_frame=True)\n",
    "X, y = df.drop(columns=['survived']), df['survived']\n",
    "\n",
    "# Define the fare_based function for classification\n",
    "def fare_based(dataf, threshold=10):\n",
    "    return np.array(dataf['fare'] > threshold).astype(int)\n",
    "\n",
    "# Convert the function into a scikit-learn compatible model\n",
    "mod = FunctionClassifier(fare_based, threshold=10)\n",
    "\n",
    "# Set up the GridSearchCV for hyperparameter tuning\n",
    "grid = GridSearchCV(mod,\n",
    "                    cv=2,\n",
    "                    param_grid={'threshold': np.linspace(0, 100, 30)},\n",
    "                    scoring={'accuracy': make_scorer(accuracy_score),\n",
    "                            'precision': make_scorer(precision_score),\n",
    "                            'recall': make_scorer(recall_score)},\n",
    "                    refit='accuracy'\n",
    "                )\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c059dbe-bcd1-4bce-bc88-c23f837e7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to visualize scores vs. threshold\n",
    "score_df = pd.DataFrame(grid.cv_results_).set_index('param_threshold')[['mean_test_accuracy', 'mean_test_precision', 'mean_test_recall']]\n",
    "\n",
    "# Plot the scores vs. threshold\n",
    "score_df.plot(figsize=(12, 5), title=\"Scores vs. Fare Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43b47c-48ba-4c48-84b9-bdf18b59c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hulearn.classification import FunctionClassifier\n",
    "\n",
    "# Assume you have trained outlier_detector and classifier beforehand\n",
    "\n",
    "# Define the make_decision function for decision-making with fallback mechanisms\n",
    "def make_decision(dataf, proba_threshold=0.8):\n",
    "    # First, create a resulting array with all the predictions\n",
    "    res = classifier.predict(dataf)\n",
    "\n",
    "    # Check confidence level, if below threshold, use fallback\n",
    "    proba = classifier.predict_proba(dataf)\n",
    "    res = np.where(proba.max(axis=1) < proba_threshold, \"doubt_fallback\", res)\n",
    "\n",
    "    # Check for outliers and use fallback if detected\n",
    "    res = np.where(outlier_detector.predict(dataf) == -1, \"outlier_fallback\", res)\n",
    "\n",
    "    # The `res` array contains the output of the decision-making process.\n",
    "    return res\n",
    "\n",
    "# Create a FunctionClassifier with the make_decision function\n",
    "fallback_model = FunctionClassifier(make_decision, proba_threshold=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c434bb0-d51f-4bde-9979-699ae9383fd1",
   "metadata": {},
   "source": [
    "In this code, outlier_detector and classifier represent your trained outlier detection and classification models. The make_decision function uses these models for decision-making with fallback mechanisms based on confidence levels and outlier detection. Finally, the FunctionClassifier is created with the make_decision function to form the fallback_model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bedf7e-4255-4761-8df3-c5f3b1cd72f8",
   "metadata": {},
   "source": [
    "Human-Learn to draw a machine learning model using interactive charts with the Penguin dataset from scikit-lego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48d369-e7b7-4ea9-920a-77adc656347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklego.datasets import load_penguins\n",
    "from hulearn.experimental.interactive import InteractiveCharts\n",
    "from hulearn.classification import InteractiveClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Penguin dataset and drop NaN values\n",
    "df = load_penguins(as_frame=True).dropna()\n",
    "\n",
    "# Create interactive charts for visualization\n",
    "clf = InteractiveCharts(df, labels=\"species\")\n",
    "\n",
    "# Add interactive charts for bill_length_mm vs. bill_depth_mm\n",
    "clf.add_chart(x=\"bill_length_mm\", y=\"bill_depth_mm\")\n",
    "\n",
    "# Add interactive charts for flipper_length_mm vs. body_mass_g\n",
    "clf.add_chart(x=\"flipper_length_mm\", y=\"body_mass_g\")\n",
    "\n",
    "# Create an InteractiveClassifier using the interactive charts data\n",
    "model = InteractiveClassifier(json_desc=clf.data())\n",
    "\n",
    "# Dummy data for plotting\n",
    "X, y = df.drop(columns=['species']), df['species']\n",
    "preds = model.fit(X, y).predict_proba(X)\n",
    "\n",
    "# Plot the interactive charts with predictions\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(3):\n",
    "    plt.subplot(131 + i)\n",
    "    plt.scatter(X['bill_length_mm'], X['bill_depth_mm'], c=preds[:, i])\n",
    "    plt.xlabel('bill_length_mm')\n",
    "    plt.ylabel('bill_depth_mm')\n",
    "    plt.title(model.classes_[i])\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(3):\n",
    "    plt.subplot(131 + i)\n",
    "    plt.scatter(X['flipper_length_mm'], X['body_mass_g'], c=preds[:, i])\n",
    "    plt.xlabel('flipper_length_mm')\n",
    "    plt.ylabel('body_mass_g')\n",
    "    plt.title(model.classes_[i])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38531cdb-e8e9-4e5d-9f1b-d3b76e562af9",
   "metadata": {},
   "source": [
    "This code utilizes Human-Learn to create interactive charts for the Penguin dataset, converts these charts into an InteractiveClassifier model, and then visualizes the predictions using scatter plots based on the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b640506-f58a-403c-911d-27223b3be54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define old and new examples with missing values\n",
    "old_example = pd.DataFrame([{\n",
    "    'island': 'Torgersen',\n",
    "    'bill_length_mm': 39.1,\n",
    "    'bill_depth_mm': 18.7,\n",
    "    'flipper_length_mm': 220.0,\n",
    "    'body_mass_g': 5750.0,\n",
    "    'sex': 'male'}\n",
    "])\n",
    "\n",
    "new_example = pd.DataFrame([{\n",
    "    'island': 'Torgersen',\n",
    "    'bill_length_mm': np.nan,\n",
    "    'bill_depth_mm': 18.7,\n",
    "    'flipper_length_mm': 220.0,\n",
    "    'body_mass_g': 5750.0,\n",
    "    'sex': 'male'}\n",
    "])\n",
    "\n",
    "# Predict probabilities for the old and new examples\n",
    "old_preds = model.predict_proba(old_example)\n",
    "new_preds = model.predict_proba(new_example)\n",
    "\n",
    "# Print the predicted probabilities for both examples\n",
    "print(\"Predicted probabilities for old example:\", old_preds)\n",
    "print(\"Predicted probabilities for new example with missing values:\", new_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e75f28-c0d1-48c5-b616-2f887c8d39c5",
   "metadata": {},
   "source": [
    "This code snippet demonstrates how the machine learning model can handle missing values, as shown by predicting probabilities for an old example without missing values (old_example) and a new example with missing values (new_example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c449b25-c863-4e3a-a407-39e89a54366c",
   "metadata": {},
   "source": [
    " Human-Learn as an outlier detection model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a20e4-d1cd-46e6-a7f7-4daf3fad0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hulearn.experimental.interactive import InteractiveCharts\n",
    "from hulearn.outlier import InteractiveOutlierDetector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create interactive charts for visualization\n",
    "charts = InteractiveCharts(df, labels=\"species\")\n",
    "charts.add_chart(x=\"bill_length_mm\", y=\"bill_depth_mm\")\n",
    "\n",
    "# Create an InteractiveOutlierDetector using the drawn data\n",
    "outlier_model = InteractiveOutlierDetector(json_desc=charts.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31df02e-687d-45d6-bcd7-fca83f31c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data for plotting\n",
    "X, y = df.drop(columns=['species']), df['species']\n",
    "preds = outlier_model.fit(X, y).predict(X)\n",
    "\n",
    "# Plot the scatter plot with outliers detected based on drawn shapes\n",
    "plt.scatter(X['bill_length_mm'], X['bill_depth_mm'], c=preds)\n",
    "plt.xlabel('bill_length_mm')\n",
    "plt.ylabel('bill_depth_mm')\n",
    "plt.title('Outlier Detection based on Drawn Shapes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e52fa-7a05-4cb5-b4d0-e6ef9b8fd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hulearn.experimental.interactive import InteractiveCharts\n",
    "from hulearn.preprocessing import InteractivePreprocessor\n",
    "\n",
    "# Create interactive charts without supplying a label column\n",
    "charts = InteractiveCharts(df, labels=[\"group_one\", \"group_two\"])\n",
    "charts.add_chart(x=\"bill_length_mm\", y=\"bill_depth_mm\")\n",
    "\n",
    "# Create an InteractivePreprocessor using the drawn data\n",
    "tfm = InteractivePreprocessor(json_desc=charts.data())\n",
    "\n",
    "# The flow for scikit-learn pipeline\n",
    "tfm.fit(df).transform(df)\n",
    "\n",
    "# The flow for pandas pipeline\n",
    "df.pipe(tfm.pandas_pipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab1f15-289f-4ba6-8fe2-9e5b658e3a93",
   "metadata": {},
   "source": [
    "InteractiveCharts are created without supplying a label column, and the drawn features are then used to create an InteractivePreprocessor. The InteractivePreprocessor can be used in both scikit-learn pipelines and pandas pipelines for featurization based on the drawn features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
